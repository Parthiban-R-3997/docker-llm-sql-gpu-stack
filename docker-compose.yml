version: '3.8'
services:
  streamlit:
    image: parthi97/llm-sql-gpu:latest
    ports:
      - "8501:8501"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    networks:
      - llm_network
    environment:
      - OLLAMA_HOST=http://host.docker.internal:11434
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - model_data:/app/models
    depends_on:
      - ollama

  ollama:
    image: parthi97/ollama:latest  # Updated image name
    ports:
      - "11434:11434"
    environment:
      - OLLAMA_HOST=0.0.0.0
      - OLLAMA_MODELS_MEMORY_USAGE=60
      - CUDA_VISIBLE_DEVICES=0
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_LAUNCH_BLOCKING=1
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
              options:
                memory: 3G
    volumes:
      - model_data:/root/.ollama
    networks:
      - llm_network

networks:
  llm_network:
    driver: bridge

volumes:
  model_data: